atari:
  policy: 'CnnPolicy'
  n_envs: 8
  n_timesteps: !!float 1e7

Pendulum-v0:
  n_envs: 8
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  n_steps: 2048
  nminibatches: 32
  lam: 0.95
  gamma: 0.99
  noptepochs: 10
  ent_coef: 0.0
  learning_rate: !!float 3e-4
  cliprange: 0.2

CartPole-v1:
  n_envs: 8
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 2048
  nminibatches: 32
  lam: 0.95
  gamma: 0.99
  noptepochs: 10
  ent_coef: 0.0
  learning_rate: !!float 3e-4
  cliprange: 0.2

MountainCar-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 256
  nminibatches: 8
  lam: 0.94
  gamma: 0.99
  noptepochs: 4
  ent_coef: .0

MountainCarContinuous-v0:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 256
  nminibatches: 8
  lam: 0.94
  gamma: 0.99
  noptepochs: 4
  ent_coef: .0

Acrobot-v1:
  normalize: true
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 256
  nminibatches: 8
  lam: 0.94
  gamma: 0.99
  noptepochs: 4
  ent_coef: .0

Bipedal-Walker-v2:
  normalize: true
  n_envs: 8
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  n_steps: 1024
  nminibatches: 16
  lam: 0.98
  gamma: 0.99
  noptepochs: 10
  ent_coef: .0
  learning_rate: !!float 3e-4
  cliprange: 0.2

LunarLander-v2:
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 1024
  nminibatches: 32
  lam: 0.98
  gamma: 0.999
  noptepochs: 4
  ent_coef: .01

LunarLanderContinuous-v2:
  n_envs: 16
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  n_steps: 1024
  nminibatches: 32
  lam: 0.98
  gamma: 0.999
  noptepochs: 4
  ent_coef: .01
