MountainCarContinuous-v0:
  normalize: "{'norm_obs': False, 'norm_reward': True}"
  n_timesteps: 1300000
  policy: 'MlpPolicy'
  learning_rate: !!float 3e-3
  buffer_size: 1000000
  batch_size: 64
  train_freq: 1
  ent_coef: 0.001
  gradient_steps: 1
  learning_starts: 1000000

Pendulum-v0:
  n_timesteps: !!float 60000
  policy: 'MlpPolicy'
  learning_rate: !!float 3e-3
  buffer_size: 50000
  batch_size: 64
  train_freq: 300
  ent_coef: 0.2
  gradient_steps: 100
  learning_starts: 1000

LunarLanderContinuous-v2:
  n_timesteps: !!float 1e5
  policy: 'MlpPolicy'
  learning_rate: !!float 3e-3
  buffer_size: 50000
  batch_size: 32
  train_freq: 1
  ent_coef: 0.2
  gradient_steps: 1
  learning_starts: 1000
  prioritized_replay: True
  prioritized_replay_alpha: 0.2

BipedalWalker-v2:
  normalize: true
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  learning_rate: !!float 3e-3
  buffer_size: 1000000
  batch_size: 32
  train_freq: 1
  ent_coef: 0.001
  gradient_steps: 1
  learning_starts: 10000

HalfCheetahBulletEnv-v0:
  normalize: "{'norm_obs': True, 'norm_reward': False}"
  n_timesteps: !!float 2e6
  policy: 'CustomSACPolicy'
  learning_rate: !!float 3e-3
  buffer_size: 1000000
  batch_size: 64
  train_freq: 1
  ent_coef: 0.01
  train_freq: 300
  gradient_steps: 100
  learning_starts: 10000

AntBulletEnv-v0:
  normalize: "{'norm_obs': True, 'norm_reward': False}"
  n_timesteps: !!float 2e6
  policy: 'CustomSACPolicy'
  learning_rate: !!float 3e-3
  buffer_size: 1000000
  batch_size: 64
  train_freq: 1
  ent_coef: 0.1
  gradient_steps: 1
  learning_starts: 10000

HopperBulletEnv-v0:
  normalize: "{'norm_obs': True, 'norm_reward': False}"
  n_timesteps: !!float 2e6
  policy: 'CustomSACPolicy'
  learning_rate: !!float 3e-3
  buffer_size: 1000000
  batch_size: 64
  train_freq: 1
  ent_coef: 0.1
  gradient_steps: 1
  learning_starts: 10000
